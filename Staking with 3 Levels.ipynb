{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/forest-cover-type-prediction/test.csv\n/kaggle/input/forest-cover-type-prediction/train.csv\n/kaggle/input/forest-cover-type-prediction/sampleSubmission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import normalize\nfrom sklearn import ensemble\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\ndf_train  = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\ndf_test = pd.read_csv('../input/forest-cover-type-prediction/test.csv')\nloc_submission = 'submission.csv'","execution_count":3,"outputs":[{"output_type":"stream","text":"CPU times: user 1.56 s, sys: 412 ms, total: 1.97 s\nWall time: 1.98 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ncols_to_normalize = ['Aspect','Slope','Horizontal_Distance_To_Hydrology',\n                     'Vertical_Distance_To_Hydrology','Hillshade_9am',\n                     'Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']\n\ndf_train[cols_to_normalize] = normalize(df_train[cols_to_normalize])\ndf_test[cols_to_normalize] = normalize(df_test[cols_to_normalize])","execution_count":4,"outputs":[{"output_type":"stream","text":"CPU times: user 920 ms, sys: 1.11 s, total: 2.03 s\nWall time: 2.02 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = [col for col in df_train.columns if col not in ['Cover_Type','Id']]\n\nfeature_cols.append('binned_elevation')\nfeature_cols.append('Horizontal_Distance_To_Roadways_Log')\nfeature_cols.append('Soil_Type12_32')\nfeature_cols.append('Soil_Type23_22_32_33')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['binned_elevation'] = [math.floor(v/50.0) for v in df_train['Elevation']]\ndf_test['binned_elevation'] = [math.floor(v/50.0) for v in df_test['Elevation']]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df_train['Horizontal_Distance_To_Roadways']]\ndf_test['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df_test['Horizontal_Distance_To_Roadways']]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Soil_Type12_32'] = df_train['Soil_Type32'] + df_train['Soil_Type12']\ndf_test['Soil_Type12_32'] = df_test['Soil_Type32'] + df_test['Soil_Type12']\ndf_train['Soil_Type23_22_32_33'] = df_train['Soil_Type23'] + df_train['Soil_Type22'] + df_train['Soil_Type32'] + df_train['Soil_Type33']\ndf_test['Soil_Type23_22_32_33'] = df_test['Soil_Type23'] + df_test['Soil_Type22'] + df_test['Soil_Type32'] + df_test['Soil_Type33']","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train / Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train[feature_cols]\nX_test = df_test[feature_cols]\n\ny_train = df_train['Cover_Type']\n\ny_train_1_2 = df_train['Cover_Type'].copy()\ny_train_1_2[~df_train['Cover_Type'].isin([1, 2])] = 999\n\ny_train_3_4_6 = df_train['Cover_Type'].copy()\ny_train_3_4_6[~df_train['Cover_Type'].isin([3, 4, 6])] = 999\n\nohe = OneHotEncoder()\ny_train_onehot = ohe.fit_transform(y_train.values.reshape(-1, 1)).toarray()\n\nohe_1_2 = OneHotEncoder()\ny_train_1_2_onehot = ohe_1_2.fit_transform(y_train_1_2.values.reshape(-1, 1)).toarray()\n\nohe_3_4_6 = OneHotEncoder()\ny_train_3_4_6_onehot = ohe_3_4_6.fit_transform(y_train_3_4_6.values.reshape(-1, 1)).toarray()\n\n\ntest_ids = df_test['Id']","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train_onehot.shape)\nprint(ohe.categories_)\n\ntest_data = np.array([1, 2, 3, 4, 5, 6, 7]).reshape(-1, 1)\nprint(ohe.transform(test_data).toarray())\n\n\nprint(y_train_1_2_onehot.shape)\nprint(ohe_1_2.categories_)\nprint(ohe_1_2.transform(test_data).toarray())\n\n\nprint(y_train_3_4_6_onehot.shape)\nprint(ohe_3_4_6.categories_)\nprint(ohe_3_4_6.transform(test_data).toarray())","execution_count":10,"outputs":[{"output_type":"stream","text":"(15120, 7)\n[array([1., 2., 3., 4., 5., 6., 7.])]\n[[1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1.]]\n(15120, 3)\n[array([  1.,   2., 999.])]\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n(15120, 4)\n[array([  3.,   4.,   6., 999.])]\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 0.]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Define Stacking Network Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\n\nclass TreesAggreator():\n    \"\"\"\n    Args:\n        clf (list of sklearn trees): classifiers of sklearn tree models.\n    \"\"\"\n    def __init__(self, clfs, num_classes):\n        self.clfs = clfs\n        self.num_classes = num_classes\n        \n        # calculate the total number of output dim\n        self.output_dim = self.num_classes * len(self.clfs)\n        \n    def fit(self, X, y, verbose=True):\n        if verbose:\n            progress_bar = tqdm_notebook\n            print('Start fitting...')\n        else:\n            progress_bar = list\n    \n        for clf in progress_bar(self.clfs):\n            # Train\n            clf.fit(X, y)\n            \n            \n    def predict(self, X, verbose=True):\n        \"\"\"\n        Returns:\n            predict meta-features based on predictions of self.clfs.\n        \"\"\"\n        if verbose:\n            progress_bar = tqdm_notebook\n            print('Start Predicting...')\n        else:\n            progress_bar = list\n        \n        meta_features = np.zeros((X.shape[0], self.output_dim))\n        col_index = 0\n        \n        for clf in progress_bar(self.clfs):\n            # Generate meta-features\n            meta_features[:, col_index: col_index+self.num_classes] = clf.predict_proba(X)\n            \n            # increment index\n            col_index += self.num_classes\n        \n        return meta_features\n            \n        \n    def fit_predict(self, X, y, verbose=True):\n        \"\"\"\n        Fit and predict X to meta-features\n        \n        Returns:\n            predicted meta-features based on predictions of self.clfs.\n        \"\"\"\n        \n        self.fit(X, y, verbose)\n        \n        return self.predict(X, verbose)\n        ","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training - Level 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrees_level_1 = [ensemble.ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=0),\n                       ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0),\n                       ensemble.GradientBoostingClassifier(n_estimators=100, random_state=0),\n                       ensemble.AdaBoostClassifier(n_estimators=50, random_state=0)]\n\n\nclfs_l1 = TreesAggreator(trees_level_1, num_classes=7)\n\nX_train_l2_all = clfs_l1.fit_predict(X_train, y_train)","execution_count":12,"outputs":[{"output_type":"stream","text":"Start fitting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60b4a061fb454c3fa151b51945846f3a"}},"metadata":{}},{"output_type":"stream","text":"\nStart Predicting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff1bb6510474da78879cdd5e23d6047"}},"metadata":{}},{"output_type":"stream","text":"\nCPU times: user 39.8 s, sys: 332 ms, total: 40.2 s\nWall time: 30.2 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Level 1: Network 2 (Label=1, 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrees_l1_1_2 = [ensemble.ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=0),\n                       ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0),\n                       ensemble.GradientBoostingClassifier(n_estimators=100, random_state=0),\n                       ensemble.AdaBoostClassifier(n_estimators=50, random_state=0)]\n\n\nclfs_l1_1_2 = TreesAggreator(trees_l1_1_2, num_classes=3)\n\nX_train_l2_1_2 = clfs_l1_1_2.fit_predict(X_train, y_train_1_2)","execution_count":13,"outputs":[{"output_type":"stream","text":"Start fitting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83dc6e62668e445b80f1df12311505c0"}},"metadata":{}},{"output_type":"stream","text":"\nStart Predicting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e827cb6089db46a1831e3bd30804e10a"}},"metadata":{}},{"output_type":"stream","text":"\nCPU times: user 22.8 s, sys: 348 ms, total: 23.1 s\nWall time: 15 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Level 1: Network 3 (Label=3, 4. 6)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrees_l1_3_4_6 = [ensemble.ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=0),\n                       ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0),\n                       ensemble.GradientBoostingClassifier(n_estimators=100, random_state=0),\n                       ensemble.AdaBoostClassifier(n_estimators=50, random_state=0)]\n\n\nclfs_l1_3_4_6 = TreesAggreator(trees_l1_3_4_6, num_classes=4)\n\nX_train_l2_3_4_6 = clfs_l1_3_4_6.fit_predict(X_train, y_train_3_4_6)","execution_count":14,"outputs":[{"output_type":"stream","text":"Start fitting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26fe3cdb3a2b4b938c348f5506b2dfee"}},"metadata":{}},{"output_type":"stream","text":"\nStart Predicting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150652b7c6a0412ab846f66e8a9e20c8"}},"metadata":{}},{"output_type":"stream","text":"\nCPU times: user 24.7 s, sys: 308 ms, total: 25 s\nWall time: 18.1 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Concatenate meta-features in 3 Networks "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(X_train_l2_all))\nprint(X_train_l2_all.shape)\nprint(X_train_l2_1_2.shape)\nprint(X_train_l2_3_4_6.shape)","execution_count":15,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n(15120, 28)\n(15120, 12)\n(15120, 16)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Training - Level 2\nTrain meta-features\nTrain Label (1, 2, 3, 4, 5, 6, 7), (1, 2, 999) and (3, 4, 6, 999)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclf_l2 = LinearRegression()\nclf_l2.fit(X_train_l2_all, y_train_onehot)\nX_train_l3_all = clf_l2.predict(X_train_l2_all)\n\nclf_l2_1_2 = LinearRegression()\nclf_l2_1_2.fit(X_train_l2_1_2, y_train_1_2_onehot)\nX_train_l3_1_2 = clf_l2_1_2.predict(X_train_l2_1_2)\n\nclf_l2_3_4_6 = LinearRegression()\nclf_l2_3_4_6.fit(X_train_l2_3_4_6, y_train_3_4_6_onehot)\nX_train_l3_3_4_6 = clf_l2_3_4_6.predict(X_train_l2_3_4_6)","execution_count":16,"outputs":[{"output_type":"stream","text":"CPU times: user 88 ms, sys: 40 ms, total: 128 ms\nWall time: 107 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Train Level 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_l3 = np.concatenate((X_train_l3_all, X_train_l3_1_2, X_train_l3_3_4_6),\n                           axis=1) # append column-wise\n\nprint(X_train_l3.shape)","execution_count":17,"outputs":[{"output_type":"stream","text":"(15120, 14)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclf_l3 = LinearRegression()\nclf_l3.fit(X_train_l3, y_train_onehot)","execution_count":18,"outputs":[{"output_type":"stream","text":"CPU times: user 136 ms, sys: 228 ms, total: 364 ms\nWall time: 94 ms\n","name":"stdout"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_test_l2_all = clfs_l1.predict(X_test)\nX_test_l2_1_2 = clfs_l1_1_2.predict(X_test)\nX_test_l2_3_4_6 = clfs_l1_3_4_6.predict(X_test)\n\nX_test_l3_all = clf_l2.predict(X_test_l2_all)\nX_test_l3_1_2 = clf_l2_1_2.predict(X_test_l2_1_2)\nX_test_l3_3_4_6 = clf_l2_3_4_6.predict(X_test_l2_3_4_6)\n\nX_test_l3 = np.concatenate((X_test_l3_all, X_test_l3_1_2, X_test_l3_3_4_6),\n                          axis=1)  # append column-wise\n\nprediction_l3 = clf_l3.predict(X_test_l3)","execution_count":19,"outputs":[{"output_type":"stream","text":"Start Predicting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7954cda544134a099ef6a6671b2f2468"}},"metadata":{}},{"output_type":"stream","text":"\nStart Predicting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcbeaff5f66145379f87ce79709a762d"}},"metadata":{}},{"output_type":"stream","text":"\nStart Predicting...\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1475c752d746909daf576e9bef8c64"}},"metadata":{}},{"output_type":"stream","text":"\nCPU times: user 2min 39s, sys: 14.2 s, total: 2min 53s\nWall time: 1min 38s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(prediction_l3[0])\nprint(prediction_l3[0].argmax() + 1)\n\nprediction_l3.argmax(axis=1) + 1","execution_count":20,"outputs":[{"output_type":"stream","text":"[ 0.43545329  0.47831349 -0.01729872  0.00826042  0.10508398 -0.01084166\n  0.00235377]\n2\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"array([2, 1, 1, ..., 3, 3, 3])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id': test_ids,\n                           'Cover_Type': prediction_l3.argmax(axis=1) + 1})\n\nsubmission.to_csv(loc_submission, index=False)","execution_count":21,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission.head())\n\nprint()\n\n!head submission.csv","execution_count":22,"outputs":[{"output_type":"stream","text":"      Id  Cover_Type\n0  15121           2\n1  15122           1\n2  15123           1\n3  15124           1\n4  15125           1\n\nId,Cover_Type\n15121,2\n15122,1\n15123,1\n15124,1\n15125,1\n15126,1\n15127,1\n15128,1\n15129,1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}