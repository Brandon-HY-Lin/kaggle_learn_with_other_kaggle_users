{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On AWS\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "if 'ec2' in getpass.getuser():\n",
    "    print('On AWS')\n",
    "    path_datasets = os.getcwd() + '/input/'\n",
    "else:\n",
    "    print('On Kaggle')\n",
    "    path_datasets = '/kaggle/input/learn-together/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>31 mins 11 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 6 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_ec2_user_pu4l3l</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>902 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         31 mins 11 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.2\n",
       "H2O cluster version age:    1 month and 6 days\n",
       "H2O cluster name:           H2O_from_python_ec2_user_pu4l3l\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    902 Mb\n",
       "H2O cluster total cores:    2\n",
       "H2O cluster allowed cores:  2\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train_org = pd.read_csv(path_datasets + \"train.csv\")\n",
    "data_test = pd.read_csv(path_datasets + \"test.csv\")\n",
    "\n",
    "data_train, data_valid = train_test_split(data_train_org, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# keywords  = ['soil']\n",
    "# all_columns = data_train_org.columns\n",
    "# col_keywords = []\n",
    "\n",
    "# for k in keywords:\n",
    "#     for col in all_columns:\n",
    "#         if k.lower() in col.lower(): \n",
    "#             col_keywords.append(col)\n",
    "            \n",
    "            \n",
    "# sequences = list(np.arange(1, 1+len(col_keywords)))\n",
    "# soil_type_dict = dict(zip(['Soil_Type{}'.format(n) for n in sequences],\n",
    "#                         sequences))\n",
    "\n",
    "# data_train['Soil_Types'] = data_train[col_keywords].idxmax(axis=1)\n",
    "# data_valid['Soil_Types'] = data_valid[col_keywords].idxmax(axis=1)\n",
    "# data_test['Soil_Types'] = data_test[col_keywords].idxmax(axis=1)\n",
    "\n",
    "# data_train['Soil_Types'] = data_train['Soil_Types'].map(soil_type_dict)\n",
    "# data_valid['Soil_Types'] = data_valid['Soil_Types'].map(soil_type_dict)\n",
    "# data_test['Soil_Types'] = data_test['Soil_Types'].map(soil_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "htrain_frame = h2o.H2OFrame(data_train)\n",
    "hvalid_frame = h2o.H2OFrame(data_valid)\n",
    "htest_frame = h2o.H2OFrame(data_test)\n",
    "# htrain_frame = h2o.H2OFrame(data_train.drop(columns=col_keywords))\n",
    "# hvalid_frame = h2o.H2OFrame(data_valid.drop(columns=col_keywords))\n",
    "# htest_frame = h2o.H2OFrame(data_test.drop(columns=col_keywords))\n",
    "\n",
    "y = 'Cover_Type'\n",
    "\n",
    "htrain_frame[y] = htrain_frame[y].asfactor()\n",
    "hvalid_frame[y] = hvalid_frame[y].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 1: Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "CPU times: user 23.5 ms, sys: 215 µs, total: 23.7 ms\n",
      "Wall time: 461 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aml = h2o.estimators.glm.H2OGeneralizedLinearEstimator( family='ordinal',\n",
    "                                                           seed=42)\n",
    "\n",
    "aml.train(y=y, training_frame=htrain_frame)\n",
    "\n",
    "aml.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Accuracy: 0.15542328042328044\n"
     ]
    }
   ],
   "source": [
    "predictions = aml.predict(hvalid_frame.drop(y))\n",
    "\n",
    "accuracy = accuracy_score(data_valid[y],\n",
    "                         predictions['predict'].as_data_frame())\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 2: Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "CPU times: user 98.5 ms, sys: 1.2 ms, total: 99.7 ms\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aml = h2o.estimators.glm.H2OGeneralizedLinearEstimator( family='multinomial',\n",
    "                                                           seed=42)\n",
    "\n",
    "aml.train(y=y, training_frame=htrain_frame)\n",
    "\n",
    "aml.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Accuracy: 0.708994708994709\n"
     ]
    }
   ],
   "source": [
    "predictions = aml.predict(hvalid_frame.drop(y))\n",
    "\n",
    "accuracy = accuracy_score(data_valid[y],\n",
    "                         predictions['predict'].as_data_frame())\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prediction_test_hframe = aml.predict(htest_frame)\n",
    "# prediction_test_hframe = aml.predict(hvalid_frame)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'ID': data_test['Id'].tolist(),\n",
    "                                    'Cover_Type': prediction_test_hframe['predict'].as_data_frame().iloc[:,0].tolist(),\n",
    "                                    })\n",
    "\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission.head())\n",
    "\n",
    "print()\n",
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
