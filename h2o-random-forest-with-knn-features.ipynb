{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/forest-cover-type-prediction/test.csv\n",
      "/kaggle/input/forest-cover-type-prediction/train.csv\n",
      "/kaggle/input/forest-cover-type-prediction/sampleSubmission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_222\"; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp_q5uvbc4\n",
      "  JVM stdout: /tmp/tmp_q5uvbc4/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp_q5uvbc4/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 21 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_rau9w4</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.2\n",
       "H2O cluster version age:    1 month and 21 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_rau9w4\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv('/kaggle/input/forest-cover-type-prediction/train.csv', index_col='Id')\n",
    "data_test = pd.read_csv('/kaggle/input/forest-cover-type-prediction/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Nearest Neighbors Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "class NearsetNeighborFeats(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    This class implement KNN features extraction\n",
    "    \"\"\"\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list)\n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps\n",
    "        self.n_classes_ = n_classes\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Set up the train set and self.NN object (Nearest Neighbors object)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict`` function\n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list),\n",
    "                                  metic=self.metric,\n",
    "                                  n_jobs=1,\n",
    "                                  algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        \n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store train labels\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Produces KNN features for every object of a dataset X  (validation/test dataset)\n",
    "        \"\"\"\n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Multiprocessing: number of threads should be `self.n_jobs`\n",
    "            \"\"\"\n",
    "            \n",
    "            test_feats = Pool(self.n_jobs).map(self.get_features_for_one,\n",
    "                                              (X[i:i+1] for i in range(X.shape[0])))\n",
    "            \n",
    "        return np.vstack(test_feats)\n",
    "    \n",
    "    \n",
    "    def get_features_for_one(self, X):\n",
    "        \"\"\"\n",
    "        Compute KNN features for a single object `x` (from the validation/test dataset)\n",
    "        That is, find nearest neighbors in train dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        NN_output = self.NN.kneigbhors(x)\n",
    "        \n",
    "        # indices of `x`'s nearest neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # distance between `x` and its neighbors\n",
    "        neighs_dist = NN_output[0][0]\n",
    "        \n",
    "        # labels in the train dataset\n",
    "        neighs_y = self.y_train[neighs]\n",
    "        \n",
    "        # Append the computed features, and then use np.hstack() to concatenate thoese features.\n",
    "        return_list = []\n",
    "        \n",
    "        \"\"\"\n",
    "        1. Average appearance of classes in K nearest neighbors.\n",
    "        Note: self.k_list would look like: [3, 8, 32]\n",
    "        \"\"\"\n",
    "        for k in self.k_list:\n",
    "            feats = np.bincount(neighs_y[:k], minlength=self.n_classes) / k    \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        2. same label streak: the larget number N,\n",
    "        such that N nearest neighbors have the same label\n",
    "        \"\"\"\n",
    "        feats = 1 + \\\n",
    "                np.where(np.append(neighs_y[:-1] != neighs_y[1:], true))[0].min(keepdims=True)\n",
    "        \n",
    "        assert len(feats) == 1\n",
    "        return_list += [feats]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        3. minimum distance to objects of each class\n",
    "        Find the first instance of a class and take its distance as features.\n",
    "        \n",
    "        If there are no neighboring objects of some classes,\n",
    "        Then set distance to that class to be 999.\n",
    "        \"\"\"\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            feats.append(np.append(neighs_dist[neighs_y == c], 999).min())\n",
    "            \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        \"\"\"\n",
    "        4. minimum *normalized* distance to objects of each class.\n",
    "        Similar to 3., but we normalize the distances\n",
    "        by the distance to the closest neighbor.\n",
    "        \n",
    "        If there are no neighboring objects of some classes,\n",
    "        Then set distance to that class to be 999.\n",
    "        \n",
    "        Add self.eps to the denominator to avoid dividing by zero error.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Valid Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid = train_test_split(data_train, test_size=0.1, random_state=42)\n",
    "\n",
    "htrain_frame = h2o.H2OFrame(df_train)\n",
    "hvalid_frame = h2o.H2OFrame(df_valid)\n",
    "htest_frame = h2o.H2OFrame(data_test)\n",
    "# htrain_frame = h2o.H2OFrame(data_train.drop(columns=col_keywords))\n",
    "# hvalid_frame = h2o.H2OFrame(data_valid.drop(columns=col_keywords))\n",
    "# htest_frame = h2o.H2OFrame(data_test.drop(columns=col_keywords))\n",
    "\n",
    "y = 'Cover_Type'\n",
    "\n",
    "htrain_frame[y] = htrain_frame[y].asfactor()\n",
    "hvalid_frame[y] = hvalid_frame[y].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "CPU times: user 328 ms, sys: 40 ms, total: 368 ms\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aml = h2o.estimators.random_forest.H2ORandomForestEstimator(\n",
    "                            max_runtime_secs=60, \n",
    "#                            max_models=1,\n",
    "                            balance_classes=True,\n",
    "                           seed=42)\n",
    "\n",
    "aml.train(y=y, training_frame=htrain_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13415853825544902\n",
      "RMSE: 0.3662765870970311\n",
      "LogLoss: 0.44879027734619426\n",
      "Mean Per-Class Error: 0.14066734205101566\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1503.0</td>\n",
       "<td>290.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>38.0</td>\n",
       "<td>7.0</td>\n",
       "<td>121.0</td>\n",
       "<td>0.2335543</td>\n",
       "<td>458 / 1,961</td></tr>\n",
       "<tr><td>345.0</td>\n",
       "<td>1316.0</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0</td>\n",
       "<td>173.0</td>\n",
       "<td>59.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.3271984</td>\n",
       "<td>640 / 1,956</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1568.0</td>\n",
       "<td>99.0</td>\n",
       "<td>26.0</td>\n",
       "<td>252.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1954849</td>\n",
       "<td>381 / 1,949</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>31.0</td>\n",
       "<td>1909.0</td>\n",
       "<td>0.0</td>\n",
       "<td>21.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0265171</td>\n",
       "<td>52 / 1,961</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>41.0</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1857.0</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0510986</td>\n",
       "<td>100 / 1,957</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>14.0</td>\n",
       "<td>156.0</td>\n",
       "<td>51.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1721.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1205927</td>\n",
       "<td>236 / 1,957</td></tr>\n",
       "<tr><td>55.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1893.0</td>\n",
       "<td>0.0302254</td>\n",
       "<td>59 / 1,952</td></tr>\n",
       "<tr><td>1908.0</td>\n",
       "<td>1667.0</td>\n",
       "<td>1828.0</td>\n",
       "<td>2059.0</td>\n",
       "<td>2110.0</td>\n",
       "<td>2090.0</td>\n",
       "<td>2031.0</td>\n",
       "<td>0.1406558</td>\n",
       "<td>1,926 / 13,693</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2     3     4     5     6     7     Error      Rate\n",
       "----  ----  ----  ----  ----  ----  ----  ---------  --------------\n",
       "1503  290   2     0     38    7     121   0.233554   458 / 1,961\n",
       "345   1316  46    0     173   59    17    0.327198   640 / 1,956\n",
       "0     4     1568  99    26    252   0     0.195485   381 / 1,949\n",
       "0     0     31    1909  0     21    0     0.0265171  52 / 1,961\n",
       "4     41    25    0     1857  30    0     0.0510986  100 / 1,957\n",
       "1     14    156   51    14    1721  0     0.120593   236 / 1,957\n",
       "55    2     0     0     2     0     1893  0.0302254  59 / 1,952\n",
       "1908  1667  1828  2059  2110  2090  2031  0.140656   1,926 / 13,693"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.8593442</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9728328</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9932082</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9986854</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9993427</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9993427</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.859344\n",
       "2    0.972833\n",
       "3    0.993208\n",
       "4    0.998685\n",
       "5    0.999343\n",
       "6    0.999343\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = aml.predict(hvalid_frame.drop(y))\n",
    "\n",
    "# accuracy = accuracy_score(data_valid[y],\n",
    "#                          predictions['predict'].as_data_frame())\n",
    "\n",
    "# print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 440 ms, total: 3.78 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction_test_hframe = aml.predict(htest_frame)\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'ID': data_test.index.tolist(),\n",
    "                                    'Cover_Type': prediction_test_hframe['predict'].as_data_frame().iloc[:,0].tolist(),\n",
    "                                    })\n",
    "\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Cover_Type\n",
      "0  15121           2\n",
      "1  15122           1\n",
      "2  15123           1\n",
      "3  15124           1\n",
      "4  15125           1\n",
      "\n",
      "ID,Cover_Type\r\n",
      "15121,2\r\n",
      "15122,1\r\n",
      "15123,1\r\n",
      "15124,1\r\n",
      "15125,1\r\n",
      "15126,1\r\n",
      "15127,1\r\n",
      "15128,1\r\n",
      "15129,1\r\n"
     ]
    }
   ],
   "source": [
    "print(submission.head())\n",
    "\n",
    "print()\n",
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
